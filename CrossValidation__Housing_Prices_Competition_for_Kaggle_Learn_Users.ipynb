{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-03T13:27:52.401408Z","iopub.execute_input":"2022-06-03T13:27:52.402350Z","iopub.status.idle":"2022-06-03T13:27:52.414349Z","shell.execute_reply.started":"2022-06-03T13:27:52.402306Z","shell.execute_reply":"2022-06-03T13:27:52.413284Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/melbourne-housing-snapshot/melb_data.csv\")\ndata.dropna(axis=0, subset=[\"Price\"], inplace=True)\n\ncols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\nx = data[cols_to_use]\ny = data.Price","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:27:52.415594Z","iopub.execute_input":"2022-06-03T13:27:52.416638Z","iopub.status.idle":"2022-06-03T13:27:52.487459Z","shell.execute_reply.started":"2022-06-03T13:27:52.416596Z","shell.execute_reply":"2022-06-03T13:27:52.486734Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"categorical_cols = [col for col in x.columns if x[col].dtype == \"object\" and x[col].nunique() < 10]\nnumeric_cols = [col for col in x.columns if x[col].dtype in [\"int64\", \"float64\"]]\n\nprint(f\"Numeric: {len(numeric_cols)} Categorical: {len(categorical_cols)}\")\n\ncols = categorical_cols + numeric_cols\nx = x[cols]","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:30:21.673427Z","iopub.execute_input":"2022-06-03T13:30:21.673813Z","iopub.status.idle":"2022-06-03T13:30:21.681819Z","shell.execute_reply.started":"2022-06-03T13:30:21.673783Z","shell.execute_reply":"2022-06-03T13:30:21.681113Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\n\nnumeric_transformer = Pipeline(steps=[\n    (\"impute\", SimpleImputer(strategy=\"mean\"))\n])\ncategorical_transformer = Pipeline(steps=[\n    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\npreprocessor = ColumnTransformer(transformers=[\n    (\"num\", numeric_transformer, numeric_cols),\n    (\"cat\", categorical_transformer, categorical_cols)\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:34:57.829232Z","iopub.execute_input":"2022-06-03T13:34:57.829643Z","iopub.status.idle":"2022-06-03T13:34:58.064147Z","shell.execute_reply.started":"2022-06-03T13:34:57.829612Z","shell.execute_reply":"2022-06-03T13:34:58.063084Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\npipeline = Pipeline(steps=[\n    (\"preprocessor\", preprocessor),\n    (\"model\", model)\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:35:58.209676Z","iopub.execute_input":"2022-06-03T13:35:58.210071Z","iopub.status.idle":"2022-06-03T13:35:58.305494Z","shell.execute_reply.started":"2022-06-03T13:35:58.210031Z","shell.execute_reply":"2022-06-03T13:35:58.304561Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# Multiply by -1 since sklearn calculates *negative* MAE\n# We set the number of folds with the cv parameter.\nscores = -1 * cross_val_score(pipeline, x, y, cv=5, scoring=\"neg_mean_absolute_error\")\n\nprint(\"MAE scores:\\n\", scores)\nprint(\"Average MAE score (across experiments):\")\nprint(scores.mean())","metadata":{"execution":{"iopub.status.busy":"2022-06-03T13:40:16.652733Z","iopub.execute_input":"2022-06-03T13:40:16.653175Z","iopub.status.idle":"2022-06-03T13:40:30.333609Z","shell.execute_reply.started":"2022-06-03T13:40:16.653138Z","shell.execute_reply":"2022-06-03T13:40:30.332492Z"},"trusted":true},"execution_count":14,"outputs":[]}]}